{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPT Code Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:54:01,943 - INFO - HTTP Request: GET https://checkip.amazonaws.com/ \"HTTP/1.1 200 \"\n",
      "2024-08-09 15:54:02,670 - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2024-08-09 15:54:02,821 - INFO - HTTP Request: GET http://127.0.0.1:7880/startup-events \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:54:05,555 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2024-08-09 15:54:12,326 - INFO - HTTP Request: HEAD http://127.0.0.1:7880/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio interface running on http://127.0.0.1:7880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:59:21,616 - INFO - Loading PDF documents\n",
      "2024-08-09 15:59:26,373 - ERROR - FAISS index not created. Please create the FAISS index first.\n",
      "2024-08-09 15:59:27,152 - INFO - Splitting documents into chunks\n",
      "2024-08-09 15:59:27,207 - INFO - Initializing and saving vectorstore\n",
      "2024-08-09 16:00:55,810 - INFO - Loading faiss with AVX2 support.\n",
      "2024-08-09 16:00:55,811 - INFO - Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "2024-08-09 16:00:55,812 - INFO - Loading faiss.\n",
      "2024-08-09 16:00:55,854 - INFO - Successfully loaded faiss.\n",
      "2024-08-09 16:00:56,088 - INFO - FAISS index created and saved successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "import logging\n",
    "import openai\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "AZURE_OPENAI_API_BASE = \"\"\n",
    "AZURE_OPENAI_API_KEY = \"\"\n",
    "VECTORSTORE_PATH = \"vectorstore\"\n",
    "faiss_index_created = False  # Flag to track FAISS index creation\n",
    "\n",
    "# Initialize LLM and Embeddings\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"300-turbo\",\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-35-turbo-16k\",\n",
    "    openai_api_base=AZURE_OPENAI_API_BASE,\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    openai_api_type='azure',\n",
    "    openai_api_key=AZURE_OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment='350-embedding',\n",
    "    openai_api_base=AZURE_OPENAI_API_BASE,\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    openai_api_type='azure',\n",
    "    openai_api_key=AZURE_OPENAI_API_KEY,\n",
    "    chunk_size=1\n",
    ")\n",
    "\n",
    "# Cell 2: Prompt Template\n",
    "prompt_template = \"\"\"\n",
    "Role: You are an expert in understanding medical terms and fetching the appropriate CPT codes. Your task is to understand the medical history provided below and identify the relevant CPT codes (Current Procedural Terminology codes) that describe the medical, surgical, and diagnostic services mentioned.\n",
    "\n",
    "General Instruction: \n",
    "1. If you encounter any irrelevant text, provide a relevant query or state \"Irrelevant text found\".\n",
    "2. Ensure that the CPT codes you select are the most specific and accurate for the procedures described.\n",
    "3. Provide a brief explanation for each selected CPT code to justify its relevance.\n",
    "\n",
    "Output Format:\n",
    "CPT Codes:\n",
    "[CPT code]: [CPT code description]\n",
    "[CPT code]: [CPT code description]\n",
    "\n",
    "Explanation:\n",
    "[Short explanation of why each CPT code was selected]\n",
    "\n",
    "Medical History of Patient:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Cell 3: Function to Create FAISS Index\n",
    "def create_faiss_index(pdf_directory):\n",
    "    global faiss_index_created\n",
    "    if not pdf_directory:\n",
    "        logging.error(\"Directory path is missing\")\n",
    "        return \"Error: Please provide a directory path.\"\n",
    "\n",
    "    if not os.path.isdir(pdf_directory):\n",
    "        logging.error(\"The provided path is not a directory\")\n",
    "        return \"Error: The provided path is not a directory.\"\n",
    "\n",
    "    pdf_files = [f for f in os.listdir(pdf_directory) if f.lower().endswith('.pdf')]\n",
    "    if not pdf_files:\n",
    "        logging.error(\"The directory does not contain any PDF files\")\n",
    "        return \"Error: The directory does not contain any PDF files.\"\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Loading PDF documents\")\n",
    "        loader = PyPDFDirectoryLoader(pdf_directory)\n",
    "        docs = loader.load()\n",
    "\n",
    "        logging.info(\"Splitting documents into chunks\")\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=3500, chunk_overlap=100)\n",
    "        chunks = splitter.split_documents(docs)\n",
    "\n",
    "        logging.info(\"Initializing and saving vectorstore\")\n",
    "        vectorstore = FAISS.from_documents(documents=chunks, embedding=embeddings)\n",
    "        vectorstore.save_local(VECTORSTORE_PATH)\n",
    "\n",
    "        faiss_index_created = True\n",
    "        logging.info(\"FAISS index created and saved successfully\")\n",
    "        return \"FAISS index created and saved successfully.\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while creating FAISS index: {str(e)}\")\n",
    "        return f\"An error occurred while creating FAISS index: {str(e)}\"\n",
    "\n",
    "\n",
    "# Cell 4: Function to Get Result\n",
    "\n",
    "# Modify the get_result function to handle query chunking\n",
    "def get_result(query):\n",
    "    if not faiss_index_created:\n",
    "        logging.error(\"FAISS index not created. Please create the FAISS index first.\")\n",
    "        return \"Error: FAISS index not created. Please create the FAISS index first.\"\n",
    "    \n",
    "    if not query:\n",
    "        logging.error(\"Query is missing\")\n",
    "        return \"Error: Please provide a query.\"\n",
    "\n",
    "    # Chunk the query if it's too long\n",
    "    query_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)  # Adjust sizes as needed\n",
    "    query_chunks = query_splitter.split_text(query)\n",
    "\n",
    "    responses = []\n",
    "    try:\n",
    "        logging.info(\"Loading vectorstore\")\n",
    "        vectorstore = FAISS.load_local(VECTORSTORE_PATH, embeddings)\n",
    "\n",
    "        logging.info(\"Initializing QA Chain Prompt Template\")\n",
    "        QA_CHAIN_PROMPT = PromptTemplate.from_template(prompt_template)\n",
    "        llm_chain = LLMChain(llm=llm, prompt=QA_CHAIN_PROMPT, callbacks=None)\n",
    "\n",
    "        document_prompt = PromptTemplate(\n",
    "            input_variables=[\"page_content\", \"source\"],\n",
    "            template=\"Context:\\ncontent:{page_content}\\nsource:{source}\",\n",
    "        )\n",
    "\n",
    "        combine_documents_chain = StuffDocumentsChain(\n",
    "            llm_chain=llm_chain,\n",
    "            document_variable_name=\"context\",\n",
    "            document_prompt=document_prompt,\n",
    "            callbacks=None,\n",
    "        )\n",
    "\n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "        for chunk in query_chunks:\n",
    "            logging.info(f\"Firing query for chunk: {chunk[:50]}...\")  # Log the start of each chunk\n",
    "            fire_query = RetrievalQA(\n",
    "                combine_documents_chain=combine_documents_chain,\n",
    "                callbacks=None,\n",
    "                retriever=retriever\n",
    "            )\n",
    "            chunk_response = fire_query(chunk)['result']\n",
    "            responses.append(chunk_response)\n",
    "\n",
    "        # Aggregate responses - simple concatenation example\n",
    "        final_response = \"\\n\".join(responses)\n",
    "        final_res = f'''\n",
    "        ::::::: EXTRACTED CPT CODE ::::::: \n",
    "        \n",
    "        {final_response}\n",
    "        '''\n",
    "        logging.info(\"Query successful\")\n",
    "        return final_res\n",
    "    except openai.error.OpenAIError:\n",
    "        logging.error(\"OpenAI API is currently unavailable. Please try again later.\")\n",
    "        return \"Error: OpenAI API is currently unavailable. Please try again later.\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\")\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "\n",
    "# Cell 5: Function to Generate PDF\n",
    "def generate_pdf(medical_history, cpt_code_output):\n",
    "    pdf_path = \"cpt_code_output.pdf\"\n",
    "    doc = SimpleDocTemplate(pdf_path, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()# Cell 6: Define Gradio Interfaces\n",
    "\n",
    "def setup_interface():\n",
    "    with gr.Tab(\"Setup FAISS Index\"):\n",
    "        with gr.Column():\n",
    "            pdf_directory_input = gr.Textbox(label=\"Enter PDF Directory Path\")\n",
    "            create_index_button = gr.Button(\"Create FAISS Index\")\n",
    "            index_creation_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "\n",
    "            def on_create_index_click(pdf_directory):\n",
    "                return create_faiss_index(pdf_directory)\n",
    "\n",
    "            create_index_button.click(on_create_index_click, inputs=pdf_directory_input, outputs=index_creation_status)\n",
    "\n",
    "    return setup_interface\n",
    "\n",
    "def query_interface():\n",
    "    with gr.Tab(\"Query Interface\"):\n",
    "        with gr.Column():\n",
    "            query_input = gr.Textbox(lines=10, label=\"Enter your query\", interactive=True)  # Reduced lines to 10\n",
    "            query_button = gr.Button(\"Get Result\")\n",
    "            query_result = gr.Textbox(label=\"Result\", interactive=False)\n",
    "            download_button = gr.File(label=\"Download PDF\")\n",
    "\n",
    "            def on_query_click(query):\n",
    "                result, pdf_path = query_and_generate_pdf(query)\n",
    "                return result, pdf_path\n",
    "\n",
    "            query_button.click(on_query_click, inputs=query_input, outputs=[query_result, download_button])\n",
    "\n",
    "    return query_interface\n",
    "\n",
    "def query_and_generate_pdf(query):\n",
    "    result = get_result(query)\n",
    "    if \"Error\" in result:\n",
    "        return result, None\n",
    "    pdf_path = generate_pdf(query, result)\n",
    "    return result, pdf_path\n",
    "\n",
    "\n",
    "# Cell 7: Combine Interfaces into Gradio App\n",
    "css = \"\"\"\n",
    "body {\n",
    "    background-color: #e0f7fa;\n",
    "    color: #006064;\n",
    "}\n",
    ".gradio-container {\n",
    "    border-radius: 10px;\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    padding: 20px;\n",
    "    background-color: #ffffff;\n",
    "    border: 1px solid #006064;\n",
    "}\n",
    ".gr-tab {\n",
    "    border-radius: 10px;\n",
    "    background-color: #b2ebf2;\n",
    "    padding: 10px;\n",
    "    margin-bottom: 10px;\n",
    "}\n",
    ".gr-button {\n",
    "    background-color: #00796b;\n",
    "    color: white;\n",
    "    font-size: 16px;\n",
    "    padding: 10px 20px;\n",
    "    border-radius: 5px;\n",
    "    margin-top: 10px;\n",
    "    border: 1px solid #004d40;\n",
    "}\n",
    ".gr-button:hover {\n",
    "    background-color: #004d40;\n",
    "}\n",
    ".gr-textbox {\n",
    "    border: 1px solid #004d40;\n",
    "    padding: 10px;\n",
    "    border-radius: 5px;\n",
    "    font-size: 14px;\n",
    "    background-color: #ffffff;\n",
    "    margin-bottom: 10px;\n",
    "}\n",
    ".gr-title {\n",
    "    font-size: 28px;\n",
    "    color: #00796b;\n",
    "    text-align: center;\n",
    "    margin-bottom: 20px;\n",
    "    margin-top: 20px;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "iface = gr.Blocks(title=\"CPT CODE EXTRACTOR\", css=css)\n",
    "with iface:\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"<h1 class='gr-title'>CPT CODE EXTRACTOR</h1>\")\n",
    "    setup_interface()\n",
    "    query_interface()\n",
    "\n",
    "# Cell 8: Run the Gradio app\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(server_port=7880)  # Specify the port\n",
    "    print(\"Gradio interface running on http://127.0.0.1:7880\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2a374ddcaa73fd52036aa2c2fee8a441b6cb7339f12cf535f6a3c5ef7fbf19d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
